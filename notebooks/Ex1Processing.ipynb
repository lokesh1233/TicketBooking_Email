{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the email modules we'll need\n",
    "import glob\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "path = '../data/raw/txtEMail/*.txt'\n",
    "files = glob.glob(path)\n",
    "appendFilesData = []\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, 'rb') as fp:\n",
    "            msg = BytesParser(policy=policy.default).parse(fp)\n",
    "            richest = ''.join(msg.get_body(preferencelist=('plain', 'html')).get_content().splitlines(keepends=True)[:])\n",
    "            appendFilesData.append({\n",
    "                \"To\":msg['To'],\n",
    "                \"From\":msg['from'],\n",
    "                \"Subject\":msg['subject'],\n",
    "                \"Body\": richest\n",
    "            })\n",
    "         \n",
    "    except IOError as exc:\n",
    "        print('Exception')\n",
    "    \n",
    "# Now the header items can be accessed as a dictionary, and any non-ASCII will\n",
    "# be converted to unicode:\n",
    "# print('To:', msg['To'])\n",
    "# print('From:', msg['from'])\n",
    "# print('Subject:', msg['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pleased', 'assist', 'best', 'rates', 'room', 'category', 'available', 'requested', 'dates', '', 'incredible', 'royal', 'escapes', 'winter', '2018', 'offer', 'incredible', 'royal', 'escape', 'double', 'occupancy', 'travel', 'dates', 'room', 'category', 'taj', 'mahal', 'hotel', 'new', 'delhi', '12th', '14th', 'march', '2019', 'taj', 'club', 'room', 'city', 'pool', 'view', 'king', 'bed', 'taj', 'lake', 'palace', 'udaipur', '14th', '15th', 'march', '2019', 'luxury', 'room', 'garden', 'non', 'lake', 'view', 'double', 'bed', 'umaid', 'bhawan', 'palace', 'jodhpur', '15th', '16th', 'march', '2019', 'palace', 'room', 'king', 'bed', 'rambagh', 'palace', 'jaipur', '20th', '22nd', 'march', '2019', 'palace', 'room', 'garden', 'courtyard', 'view', 'total', 'amount', 'inr', '326861', 'inclusive', 'taxes', '6', 'nights', 'stay', 'inclusions', '', '', 'minimum', '6', 'nights', 'stay', '', 'offer']\n"
     ]
    }
   ],
   "source": [
    "## need to check and execute the code\n",
    "\n",
    "text = appendFilesData[1][\"Body\"]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = stripped #[word for word in stripped if word.isalnum()]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])\n",
    "\n",
    "##' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## need to check and execute the code for named entity\n",
    "\n",
    "# #appendFilesData[0][\"Body\"]\n",
    "\n",
    "# import nltk\n",
    "# doc = appendFilesData[1][\"Body\"]\n",
    "# # tokenize doc\n",
    "# tokenized_doc = nltk.word_tokenize(' '.join(words))\n",
    " \n",
    "# # tag sentences and use nltk's Named Entity Chunker\n",
    "# tagged_sentences = nltk.pos_tag(tokenized_doc)\n",
    "# ne_chunked_sents = nltk.ne_chunk(tagged_sentences)\n",
    " \n",
    "# # extract all named entities\n",
    "# named_entities = []\n",
    "# for tagged_tree in ne_chunked_sents:\n",
    "#     if hasattr(tagged_tree, 'label'):\n",
    "#         entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) #\n",
    "#         entity_type = tagged_tree.label() # get NE category\n",
    "#         named_entities.append((entity_name, entity_type))\n",
    "# print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = appendFilesData[2][\"Body\"]\n",
    "\n",
    "#print(sent_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = EXAMPLE_TEXT\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#print(word_tokens)\n",
    "#print(filtered_sentence)\n",
    "\n",
    "pos_tagTokens = nltk.pos_tag(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkGram = r\"\"\"Chunk: {<CD.?>*<TO.?>*<CD>+<CD>?}\"\"\"\n",
    "\n",
    "#pattern = \"\"\"P: {<CD><TO><CD><NNP><CD>?}\"\"\"\n",
    "pattern = \"\"\"P: {<NNP.*><CD><TO><CD><NNP><CD><NNP+>?}\"\"\"\n",
    "\n",
    "chunkParser = nltk.RegexpParser(pattern)\n",
    "chunked = chunkParser.parse(pos_tagTokens)\n",
    "            \n",
    "#print(chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "for subtree in chunked.subtrees():\n",
    "    if i > 0:\n",
    "        print(subtree)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  We/PRP\n",
      "  are/VBP\n",
      "  pleased/JJ\n",
      "  to/TO\n",
      "  assist/VB\n",
      "  you/PRP\n",
      "  with/IN\n",
      "  the/DT\n",
      "  best/JJS\n",
      "  rates/NNS\n",
      "  and/CC\n",
      "  room/NN\n",
      "  category/NN\n",
      "  available/JJ\n",
      "  for/IN\n",
      "  the/DT\n",
      "  requested/JJ\n",
      "  dates/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  Incredible/JJ\n",
      "  (Chunk Royal/NNP Escapes/NNP Winter/NNP)\n",
      "  2018/CD\n",
      "  (Chunk\n",
      "    Offer/NNP\n",
      "    Incredible/NNP\n",
      "    Royal/NNP\n",
      "    Escape/NNP\n",
      "    Double/NNP\n",
      "    Occupancy/NNP\n",
      "    Travel/NNP\n",
      "    Dates/NNP\n",
      "    Room/NNP\n",
      "    Category/NNP\n",
      "    Taj/NNP\n",
      "    Mahal/NNP\n",
      "    Hotel/NNP\n",
      "    New/NNP\n",
      "    Delhi/NNP)\n",
      "  12th/CD\n",
      "  to/TO\n",
      "  14th/CD\n",
      "  (Chunk March/NNP)\n",
      "  2019/CD\n",
      "  (Chunk\n",
      "    Taj/NNP\n",
      "    Club/NNP\n",
      "    Room/NNP\n",
      "    City/NNP\n",
      "    Or/NNP\n",
      "    Pool/NNP\n",
      "    View/NNP\n",
      "    King/NNP\n",
      "    Bed/NNP\n",
      "    Taj/NNP\n",
      "    Lake/NNP\n",
      "    Palace/NNP\n",
      "    Udaipur/NNP)\n",
      "  14th/CD\n",
      "  to/TO\n",
      "  15th/CD\n",
      "  (Chunk March/NNP)\n",
      "  2019/CD\n",
      "  (Chunk\n",
      "    Luxury/NNP\n",
      "    Room/NNP\n",
      "    Garden/NNP\n",
      "    Non/NNP\n",
      "    Lake/NNP\n",
      "    View/NNP\n",
      "    Double/NNP\n",
      "    Bed/NNP\n",
      "    Umaid/NNP\n",
      "    Bhawan/NNP\n",
      "    Palace/NNP\n",
      "    Jodhpur/NNP)\n",
      "  15th/CD\n",
      "  to/TO\n",
      "  16th/CD\n",
      "  (Chunk March/NNP)\n",
      "  2019/CD\n",
      "  (Chunk\n",
      "    Palace/NNP\n",
      "    Room/NNP\n",
      "    King/NNP\n",
      "    Bed/NNP\n",
      "    Rambagh/NNP\n",
      "    Palace/NNP\n",
      "    Jaipur/NNP)\n",
      "  20th/CD\n",
      "  to/TO\n",
      "  22nd/CD\n",
      "  (Chunk March/NNP)\n",
      "  2019/CD\n",
      "  (Chunk Palace/NNP Room/NNP Garden/NNP)\n",
      "  or/CC\n",
      "  (Chunk Courtyard/NNP View/NNP TOTAL/NNP AMOUNT/NNP INR/NNP)\n",
      "  3,26,861/-/JJ\n",
      "  inclusive/NN\n",
      "  of/IN\n",
      "  taxes/NNS\n",
      "  for/IN\n",
      "  6/CD\n",
      "  nights/NNS\n",
      "  stay/JJ\n",
      "  Inclusions/NNS\n",
      "  :/:\n",
      "  (Chunk */VB Minimum/NNP)\n",
      "  6/CD\n",
      "  nights/NNS\n",
      "  stay/VBP\n",
      "  */JJ\n",
      "  (Chunk Offer/NNP)\n",
      "  includes/VBZ\n",
      "  accommodation/NN\n",
      "  ,/,\n",
      "  breakfast/NN\n",
      "  and/CC\n",
      "  15/CD\n",
      "  %/NN\n",
      "  discount/NN\n",
      "  on/IN\n",
      "  food/NN\n",
      "  and/CC\n",
      "  soft/JJ\n",
      "  beverages/NNS\n",
      "  &/CC\n",
      "  (Chunk Spa/NNP)\n",
      "  treatments/NNS\n",
      "  (Chunk */VBP Daily/NNP Yoga/NNP)\n",
      "  sessions/NNS\n",
      "  */VBP\n",
      "  Stays/NNS\n",
      "  can/MD\n",
      "  be/VB\n",
      "  extended/VBN\n",
      "  on/IN\n",
      "  a/DT\n",
      "  pro-rata/JJ\n",
      "  basis/NN\n",
      "  beyond/IN\n",
      "  the/DT\n",
      "  minimum/JJ\n",
      "  stipulated/VBD\n",
      "  6/CD\n",
      "  nights/NNS\n",
      "  */JJ\n",
      "  (Chunk CANCELLATION/NNP POLICY/NNP)\n",
      "  -/:\n",
      "  Reservations/NNS\n",
      "  must/MD\n",
      "  be/VB\n",
      "  cancelled/VBN\n",
      "  by/IN\n",
      "  2pm/CD\n",
      "  -/:\n",
      "  30/CD\n",
      "  days/NNS\n",
      "  prior/RB\n",
      "  to/TO\n",
      "  arrival/VB\n",
      "  to/TO\n",
      "  avoid/VB\n",
      "  a/DT\n",
      "  penalty/NN\n",
      "  of/IN\n",
      "  full/JJ\n",
      "  stay/NN\n",
      "  plus/CC\n",
      "  taxes/NNS\n",
      "  ./.)\n",
      "(Chunk Royal/NNP Escapes/NNP Winter/NNP)\n",
      "(Chunk\n",
      "  Offer/NNP\n",
      "  Incredible/NNP\n",
      "  Royal/NNP\n",
      "  Escape/NNP\n",
      "  Double/NNP\n",
      "  Occupancy/NNP\n",
      "  Travel/NNP\n",
      "  Dates/NNP\n",
      "  Room/NNP\n",
      "  Category/NNP\n",
      "  Taj/NNP\n",
      "  Mahal/NNP\n",
      "  Hotel/NNP\n",
      "  New/NNP\n",
      "  Delhi/NNP)\n",
      "(Chunk March/NNP)\n",
      "(Chunk\n",
      "  Taj/NNP\n",
      "  Club/NNP\n",
      "  Room/NNP\n",
      "  City/NNP\n",
      "  Or/NNP\n",
      "  Pool/NNP\n",
      "  View/NNP\n",
      "  King/NNP\n",
      "  Bed/NNP\n",
      "  Taj/NNP\n",
      "  Lake/NNP\n",
      "  Palace/NNP\n",
      "  Udaipur/NNP)\n",
      "(Chunk March/NNP)\n",
      "(Chunk\n",
      "  Luxury/NNP\n",
      "  Room/NNP\n",
      "  Garden/NNP\n",
      "  Non/NNP\n",
      "  Lake/NNP\n",
      "  View/NNP\n",
      "  Double/NNP\n",
      "  Bed/NNP\n",
      "  Umaid/NNP\n",
      "  Bhawan/NNP\n",
      "  Palace/NNP\n",
      "  Jodhpur/NNP)\n",
      "(Chunk March/NNP)\n",
      "(Chunk\n",
      "  Palace/NNP\n",
      "  Room/NNP\n",
      "  King/NNP\n",
      "  Bed/NNP\n",
      "  Rambagh/NNP\n",
      "  Palace/NNP\n",
      "  Jaipur/NNP)\n",
      "(Chunk March/NNP)\n",
      "(Chunk Palace/NNP Room/NNP Garden/NNP)\n",
      "(Chunk Courtyard/NNP View/NNP TOTAL/NNP AMOUNT/NNP INR/NNP)\n",
      "(Chunk */VB Minimum/NNP)\n",
      "(Chunk Offer/NNP)\n",
      "(Chunk Spa/NNP)\n",
      "(Chunk */VBP Daily/NNP Yoga/NNP)\n",
      "(Chunk CANCELLATION/NNP POLICY/NNP)\n",
      "(S\n",
      "  */NN\n",
      "  (Chunk Credit/NNP card/NN)\n",
      "  details/NNS\n",
      "  required/VBN\n",
      "  within/IN\n",
      "  72/CD\n",
      "  hours/NNS\n",
      "  of/IN\n",
      "  processing/VBG\n",
      "  the/DT\n",
      "  reservation/NN\n",
      "  (/(\n",
      "  depending/VBG\n",
      "  upon/IN\n",
      "  the/DT\n",
      "  day/NN\n",
      "  the/DT\n",
      "  reservation/NN\n",
      "  is/VBZ\n",
      "  processed/VBN\n",
      "  )/)\n",
      "  */VBZ\n",
      "  No/DT\n",
      "  show/NN\n",
      "  charge/NN\n",
      "  is/VBZ\n",
      "  100/CD\n",
      "  %/NN\n",
      "  of/IN\n",
      "  full/JJ\n",
      "  stay/NN)\n",
      "(Chunk Credit/NNP card/NN)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = EXAMPLE_TEXT\n",
    "sample_text = EXAMPLE_TEXT\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\lokesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lokesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m                         \u001b[0mbinary_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gswin32c.exe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gswin64c.exe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m                         \u001b[0menv_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m                     )\n\u001b[0;32m    799\u001b[0m                 ]\n",
      "\u001b[1;32mc:\\users\\lokesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    694\u001b[0m     return next(\n\u001b[0;32m    695\u001b[0m         find_binary_iter(\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         )\n\u001b[0;32m    698\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\lokesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \"\"\"\n\u001b[0;32m    679\u001b[0m     for file in find_file_iter(\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m     ):\n\u001b[0;32m    682\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lokesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n\\n  For more information on %s, see:\\n    <%s>'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('We', 'PRP'), ('are', 'VBP'), ('pleased', 'JJ'), ('to', 'TO'), ('assist', 'VB'), ('you', 'PRP'), ('with', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('rates', 'NNS'), ('and', 'CC'), ('room', 'NN'), ('category', 'NN'), ('available', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('requested', 'JJ'), ('dates', 'NNS'), ('.', '.'), ('Incredible', 'JJ'), Tree('NE', [('Royal', 'NNP'), ('Escapes', 'NNP')]), ('Winter', 'NNP'), ('2018', 'CD'), ('Offer', 'NNP'), ('Incredible', 'NNP'), ('Royal', 'NNP'), ('Escape', 'NNP'), ('Double', 'NNP'), ('Occupancy', 'NNP'), ('Travel', 'NNP'), ('Dates', 'NNP'), ('Room', 'NNP'), ('Category', 'NNP'), ('Taj', 'NNP'), ('Mahal', 'NNP'), ('Hotel', 'NNP'), ('New', 'NNP'), ('Delhi', 'NNP'), ('12th', 'CD'), ('to', 'TO'), ('14th', 'CD'), ('March', 'NNP'), ('2019', 'CD'), ('Taj', 'NNP'), ('Club', 'NNP'), ('Room', 'NNP'), ('City', 'NNP'), ('Or', 'NNP'), ('Pool', 'NNP'), ('View', 'NNP'), ('King', 'NNP'), ('Bed', 'NNP'), ('Taj', 'NNP'), ('Lake', 'NNP'), ('Palace', 'NNP'), ('Udaipur', 'NNP'), ('14th', 'CD'), ('to', 'TO'), ('15th', 'CD'), ('March', 'NNP'), ('2019', 'CD'), Tree('NE', [('Luxury', 'NNP'), ('Room', 'NNP'), ('Garden', 'NNP'), ('Non', 'NNP'), ('Lake', 'NNP'), ('View', 'NNP'), ('Double', 'NNP'), ('Bed', 'NNP'), ('Umaid', 'NNP'), ('Bhawan', 'NNP'), ('Palace', 'NNP')]), ('Jodhpur', 'NNP'), ('15th', 'CD'), ('to', 'TO'), ('16th', 'CD'), ('March', 'NNP'), ('2019', 'CD'), Tree('NE', [('Palace', 'NNP'), ('Room', 'NNP'), ('King', 'NNP'), ('Bed', 'NNP'), ('Rambagh', 'NNP'), ('Palace', 'NNP')]), ('Jaipur', 'NNP'), ('20th', 'CD'), ('to', 'TO'), ('22nd', 'CD'), ('March', 'NNP'), ('2019', 'CD'), Tree('NE', [('Palace', 'NNP'), ('Room', 'NNP'), ('Garden', 'NNP')]), ('or', 'CC'), Tree('NE', [('Courtyard', 'NNP'), ('View', 'NNP')]), ('TOTAL', 'NNP'), ('AMOUNT', 'NNP'), ('INR', 'NNP'), ('3,26,861/-', 'JJ'), ('inclusive', 'NN'), ('of', 'IN'), ('taxes', 'NNS'), ('for', 'IN'), ('6', 'CD'), ('nights', 'NNS'), ('stay', 'JJ'), ('Inclusions', 'NNS'), (':', ':'), ('*', 'VB'), ('Minimum', 'NNP'), ('6', 'CD'), ('nights', 'NNS'), ('stay', 'VBP'), ('*', 'JJ'), ('Offer', 'NNP'), ('includes', 'VBZ'), ('accommodation', 'NN'), (',', ','), ('breakfast', 'NN'), ('and', 'CC'), ('15', 'CD'), ('%', 'NN'), ('discount', 'NN'), ('on', 'IN'), ('food', 'NN'), ('and', 'CC'), ('soft', 'JJ'), ('beverages', 'NNS'), ('&', 'CC'), ('Spa', 'NNP'), ('treatments', 'NNS'), ('*', 'VBP'), Tree('NE', [('Daily', 'NNP'), ('Yoga', 'NNP')]), ('sessions', 'NNS'), ('*', 'VBP'), ('Stays', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('extended', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('pro-rata', 'JJ'), ('basis', 'NN'), ('beyond', 'IN'), ('the', 'DT'), ('minimum', 'JJ'), ('stipulated', 'VBD'), ('6', 'CD'), ('nights', 'NNS'), ('*', 'JJ'), ('CANCELLATION', 'NNP'), Tree('NE', [('POLICY', 'NNP')]), ('-', ':'), ('Reservations', 'NNS'), ('must', 'MD'), ('be', 'VB'), ('cancelled', 'VBN'), ('by', 'IN'), ('2pm', 'CD'), ('-', ':'), ('30', 'CD'), ('days', 'NNS'), ('prior', 'RB'), ('to', 'TO'), ('arrival', 'VB'), ('to', 'TO'), ('avoid', 'VB'), ('a', 'DT'), ('penalty', 'NN'), ('of', 'IN'), ('full', 'JJ'), ('stay', 'NN'), ('plus', 'CC'), ('taxes', 'NNS'), ('.', '.'), ('*', 'VB'), Tree('NE', [('Credit', 'NNP')]), ('card', 'NN'), ('details', 'NNS'), ('required', 'VBN'), ('within', 'IN'), ('72', 'CD'), ('hours', 'NNS'), ('of', 'IN'), ('processing', 'VBG'), ('the', 'DT'), ('reservation', 'NN'), ('(', '('), ('depending', 'VBG'), ('upon', 'IN'), ('the', 'DT'), ('day', 'NN'), ('the', 'DT'), ('reservation', 'NN'), ('is', 'VBZ'), ('processed', 'VBN'), (')', ')'), ('*', 'VBZ'), ('No', 'DT'), ('show', 'NN'), ('charge', 'NN'), ('is', 'VBZ'), ('100', 'CD'), ('%', 'NN'), ('of', 'IN'), ('full', 'JJ'), ('stay', 'NN')])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EXAMPLE_TEXT\n",
    "\n",
    "#appendFilesData[1][\"Body\"]\n",
    "\n",
    "nltk.ne_chunk(pos_tagTokens, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import state_union\n",
    "# from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# train_text = appendFilesData[1][\"Body\"]\n",
    "# sample_text = appendFilesData[5][\"Body\"]\n",
    "\n",
    "# custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "# tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "# def process_content():\n",
    "#     try:\n",
    "#         for i in tokenized[5:]:\n",
    "#             words = nltk.word_tokenize(i)\n",
    "#             tagged = nltk.pos_tag(words)\n",
    "\n",
    "#             chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "#                                     }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "#             chunkParser = nltk.RegexpParser(chunkGram)\n",
    "#             chunked = chunkParser.parse(tagged)\n",
    "\n",
    "#             chunked.draw()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "\n",
    "# process_content()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import state_union\n",
    "# from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# train_text = appendFilesData[1][\"Body\"]\n",
    "# sample_text = appendFilesData[0][\"Body\"]\n",
    "\n",
    "# custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "# tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "# def process_content():\n",
    "#     try:\n",
    "#         for i in tokenized[5:]:\n",
    "#             words = nltk.word_tokenize(i)\n",
    "#             tagged = nltk.pos_tag(words)\n",
    "#             namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
    "#             namedEnt.draw()\n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "\n",
    "\n",
    "# process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requires eGenix.com mx Base Distribution\n",
      "http://www.egenix.com/products/python/mxBase/\n",
      "['2018', '2019', '2019', '2019']\n",
      "-----------------------------------------------------------\n",
      "We are pleased to assist you with the best rates and room category\n",
      "available for the requested dates.\n",
      "\n",
      " \n",
      "\n",
      "Incredible Royal Escapes Winter <TIMEX2>2018</TIMEX2> Offer\n",
      "\n",
      " \n",
      "\n",
      "Incredible Royal Escape\n",
      "\n",
      "Double Occupancy \n",
      "\n",
      " \n",
      "\n",
      "Travel Dates \n",
      "\n",
      "Room Category\n",
      "\n",
      " \n",
      "\n",
      "Taj Mahal Hotel New Delhi\n",
      "\n",
      "12-03-<TIMEX2>2019</TIMEX2> to 14-03-<TIMEX2>2019</TIMEX2>\n",
      "\n",
      "Taj Club Room City Or Pool View King Bed\n",
      "\n",
      " \n",
      "\n",
      "Taj Lake Palace Udaipur\n",
      "\n",
      "14th to 15th March <TIMEX2>2019</TIMEX2>\n",
      "\n",
      "Luxury Room Garden Non Lake View Double Bed\n",
      "\n",
      " \n",
      "\n",
      "Umaid Bhawan Palace Jodhpur\n",
      "\n",
      "15th to 16th March <TIMEX2>2019</TIMEX2>\n",
      "\n",
      "Palace Room King Bed\n",
      "\n",
      " \n",
      "\n",
      "Rambagh Palace Jaipur\n",
      "\n",
      "20th to 22nd March <TIMEX2>2019</TIMEX2>\n",
      "\n",
      "Palace Room Garden or Courtyard View\n",
      "\n",
      " \n",
      "\n",
      "\t \n",
      "\n",
      "TOTAL AMOUNT\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "INR 3,26,861/- inclusive of taxes for 6 nights stay\n",
      "\n",
      " \n",
      "\n",
      "Inclusions:\n",
      "\n",
      " \n",
      "\n",
      "*         Minimum 6 nights stay \n",
      "\n",
      " \n",
      "\n",
      "*         Offer includes accommodation , breakfast and 15% discount on\n",
      "food and soft beverages & Spa treatments\n",
      "\n",
      " \n",
      "\n",
      "*         Daily Yoga sessions\n",
      "\n",
      " \n",
      "\n",
      "*         Stays can be extended on a pro-rata basis beyond the minimum\n",
      "stipulated 6 nights\n",
      "\n",
      " \n",
      "\n",
      "\t \n",
      "\n",
      "*         CANCELLATION POLICY - Reservations must be cancelled by 2pm -\n",
      "30 days prior to arrival to avoid a penalty of full stay plus taxes.\n",
      "\n",
      " \n",
      "\n",
      "*\tCredit card details required within 72 hours of processing the\n",
      "reservation (depending upon the day the reservation is processed)\n",
      "*\tNo show charge is 100 % of full stay\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code for tagging temporal expressions in text\n",
    "# For details of the TIMEX format, see http://timex2.mitre.org/\n",
    "\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Requires eGenix.com mx Base Distribution\n",
    "# http://www.egenix.com/products/python/mxBase/\n",
    "try:\n",
    "    from mx.DateTime import *\n",
    "except ImportError:\n",
    "    print(\"\"\"\n",
    "Requires eGenix.com mx Base Distribution\n",
    "http://www.egenix.com/products/python/mxBase/\"\"\")\n",
    "\n",
    "# Predefined strings.\n",
    "numbers = \"(^a(?=\\s)|one|two|three|four|five|six|seven|eight|nine|ten| \\\n",
    "          eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen| \\\n",
    "          eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty| \\\n",
    "          ninety|hundred|thousand)\"\n",
    "day = \"(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\"\n",
    "week_day = \"(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\"\n",
    "month = \"(january|february|march|april|may|june|july|august|september| \\\n",
    "          october|november|december)\"\n",
    "dmy = \"(year|day|week|month)\"\n",
    "rel_day = \"(today|yesterday|tomorrow|tonight|tonite)\"\n",
    "exp1 = \"(before|after|earlier|later|ago)\"\n",
    "exp2 = \"(this|next|last)\"\n",
    "iso = \"\\d+[/-]\\d+[/-]\\d+ \\d+:\\d+:\\d+\\.\\d+\"\n",
    "year = \"((?<=\\s)\\d{4}|^\\d{4})\"\n",
    "regxp1 = \"((\\d+|(\" + numbers + \"[-\\s]?)+) \" + dmy + \"s? \" + exp1 + \")\"\n",
    "regxp2 = \"(\" + exp2 + \" (\" + dmy + \"|\" + week_day + \"|\" + month + \"))\"\n",
    "\n",
    "reg1 = re.compile(regxp1, re.IGNORECASE)\n",
    "reg2 = re.compile(regxp2, re.IGNORECASE)\n",
    "reg3 = re.compile(rel_day, re.IGNORECASE)\n",
    "reg4 = re.compile(iso)\n",
    "reg5 = re.compile(year)\n",
    "\n",
    "def tag(text):\n",
    "\n",
    "    # Initialization\n",
    "    timex_found = []\n",
    "\n",
    "    # re.findall() finds all the substring matches, keep only the full\n",
    "    # matching string. Captures expressions such as 'number of days' ago, etc.\n",
    "    found = reg1.findall(text)\n",
    "    found = [a[0] for a in found if len(a) > 1]\n",
    "    for timex in found:\n",
    "        timex_found.append(timex)\n",
    "\n",
    "    # Variations of this thursday, next year, etc\n",
    "    found = reg2.findall(text)\n",
    "    found = [a[0] for a in found if len(a) > 1]\n",
    "    for timex in found:\n",
    "        timex_found.append(timex)\n",
    "\n",
    "    # today, tomorrow, etc\n",
    "    found = reg3.findall(text)\n",
    "    for timex in found:\n",
    "        timex_found.append(timex)\n",
    "\n",
    "    # ISO\n",
    "    found = reg4.findall(text)\n",
    "    for timex in found:\n",
    "        timex_found.append(timex)\n",
    "\n",
    "    # Year\n",
    "    found = reg5.findall(text)\n",
    "    for timex in found:\n",
    "        timex_found.append(timex)\n",
    "\n",
    "    # Tag only temporal expressions which haven't been tagged.\n",
    "    for timex in timex_found:\n",
    "        text = re.sub(timex + '(?!</TIMEX2>)', '<TIMEX2>' + timex + '</TIMEX2>', text)\n",
    "    print(timex_found)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Hash function for week days to simplify the grounding task.\n",
    "# [Mon..Sun] -> [0..6]\n",
    "hashweekdays = {\n",
    "    'Monday': 0,\n",
    "    'Tuesday': 1,\n",
    "    'Wednesday': 2,\n",
    "    'Thursday': 3,\n",
    "    'Friday': 4,\n",
    "    'Saturday': 5,\n",
    "    'Sunday': 6}\n",
    "\n",
    "# Hash function for months to simplify the grounding task.\n",
    "# [Jan..Dec] -> [1..12]\n",
    "hashmonths = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12}\n",
    "\n",
    "# Hash number in words into the corresponding integer value\n",
    "def hashnum(number):\n",
    "    if re.match(r'one|^a\\b', number, re.IGNORECASE):\n",
    "        return 1\n",
    "    if re.match(r'two', number, re.IGNORECASE):\n",
    "        return 2\n",
    "    if re.match(r'three', number, re.IGNORECASE):\n",
    "        return 3\n",
    "    if re.match(r'four', number, re.IGNORECASE):\n",
    "        return 4\n",
    "    if re.match(r'five', number, re.IGNORECASE):\n",
    "        return 5\n",
    "    if re.match(r'six', number, re.IGNORECASE):\n",
    "        return 6\n",
    "    if re.match(r'seven', number, re.IGNORECASE):\n",
    "        return 7\n",
    "    if re.match(r'eight', number, re.IGNORECASE):\n",
    "        return 8\n",
    "    if re.match(r'nine', number, re.IGNORECASE):\n",
    "        return 9\n",
    "    if re.match(r'ten', number, re.IGNORECASE):\n",
    "        return 10\n",
    "    if re.match(r'eleven', number, re.IGNORECASE):\n",
    "        return 11\n",
    "    if re.match(r'twelve', number, re.IGNORECASE):\n",
    "        return 12\n",
    "    if re.match(r'thirteen', number, re.IGNORECASE):\n",
    "        return 13\n",
    "    if re.match(r'fourteen', number, re.IGNORECASE):\n",
    "        return 14\n",
    "    if re.match(r'fifteen', number, re.IGNORECASE):\n",
    "        return 15\n",
    "    if re.match(r'sixteen', number, re.IGNORECASE):\n",
    "        return 16\n",
    "    if re.match(r'seventeen', number, re.IGNORECASE):\n",
    "        return 17\n",
    "    if re.match(r'eighteen', number, re.IGNORECASE):\n",
    "        return 18\n",
    "    if re.match(r'nineteen', number, re.IGNORECASE):\n",
    "        return 19\n",
    "    if re.match(r'twenty', number, re.IGNORECASE):\n",
    "        return 20\n",
    "    if re.match(r'thirty', number, re.IGNORECASE):\n",
    "        return 30\n",
    "    if re.match(r'forty', number, re.IGNORECASE):\n",
    "        return 40\n",
    "    if re.match(r'fifty', number, re.IGNORECASE):\n",
    "        return 50\n",
    "    if re.match(r'sixty', number, re.IGNORECASE):\n",
    "        return 60\n",
    "    if re.match(r'seventy', number, re.IGNORECASE):\n",
    "        return 70\n",
    "    if re.match(r'eighty', number, re.IGNORECASE):\n",
    "        return 80\n",
    "    if re.match(r'ninety', number, re.IGNORECASE):\n",
    "        return 90\n",
    "    if re.match(r'hundred', number, re.IGNORECASE):\n",
    "        return 100\n",
    "    if re.match(r'thousand', number, re.IGNORECASE):\n",
    "      return 1000\n",
    "\n",
    "# Given a timex_tagged_text and a Date object set to base_date,\n",
    "# returns timex_grounded_text\n",
    "def ground(tagged_text, base_date):\n",
    "\n",
    "    # Find all identified timex and put them into a list\n",
    "    timex_regex = re.compile(r'<TIMEX2>.*?</TIMEX2>', re.DOTALL)\n",
    "    timex_found = timex_regex.findall(tagged_text)\n",
    "    timex_found = map(lambda timex:re.sub(r'</?TIMEX2.*?>', '', timex), \\\n",
    "                timex_found)\n",
    "\n",
    "    # Calculate the new date accordingly\n",
    "    for timex in timex_found:\n",
    "        timex_val = 'UNKNOWN' # Default value\n",
    "\n",
    "        timex_ori = timex   # Backup original timex for later substitution\n",
    "\n",
    "        # If numbers are given in words, hash them into corresponding numbers.\n",
    "        # eg. twenty five days ago --> 25 days ago\n",
    "        if re.search(numbers, timex, re.IGNORECASE):\n",
    "            split_timex = re.split(r'\\s(?=days?|months?|years?|weeks?)', \\\n",
    "                                                              timex, re.IGNORECASE)\n",
    "            value = split_timex[0]\n",
    "            unit = split_timex[1]\n",
    "            num_list = map(lambda s:hashnum(s),re.findall(numbers + '+', \\\n",
    "                                          value, re.IGNORECASE))\n",
    "            timex = sum(num_list) + ' ' + unit\n",
    "\n",
    "        # If timex matches ISO format, remove 'time' and reorder 'date'\n",
    "        if re.match(r'\\d+[/-]\\d+[/-]\\d+ \\d+:\\d+:\\d+\\.\\d+', timex):\n",
    "            dmy = re.split(r'\\s', timex)[0]\n",
    "            dmy = re.split(r'/|-', dmy)\n",
    "            timex_val = str(dmy[2]) + '-' + str(dmy[1]) + '-' + str(dmy[0])\n",
    "\n",
    "        # Specific dates\n",
    "        elif re.match(r'\\d{4}', timex):\n",
    "            timex_val = str(timex)\n",
    "\n",
    "        # Relative dates\n",
    "        elif re.match(r'tonight|tonite|today', timex, re.IGNORECASE):\n",
    "            timex_val = str(base_date)\n",
    "        elif re.match(r'yesterday', timex, re.IGNORECASE):\n",
    "            timex_val = str(base_date + RelativeDateTime(days=-1))\n",
    "        elif re.match(r'tomorrow', timex, re.IGNORECASE):\n",
    "            timex_val = str(base_date + RelativeDateTime(days=+1))\n",
    "\n",
    "        # Weekday in the previous week.\n",
    "        elif re.match(r'last ' + week_day, timex, re.IGNORECASE):\n",
    "            day = hashweekdays[timex.split()[1]]\n",
    "            timex_val = str(base_date + RelativeDateTime(weeks=-1, \\\n",
    "                            weekday=(day,0)))\n",
    "\n",
    "        # Weekday in the current week.\n",
    "        elif re.match(r'this ' + week_day, timex, re.IGNORECASE):\n",
    "            day = hashweekdays[timex.split()[1]]\n",
    "            timex_val = str(base_date + RelativeDateTime(weeks=0, \\\n",
    "                            weekday=(day,0)))\n",
    "\n",
    "        # Weekday in the following week.\n",
    "        elif re.match(r'next ' + week_day, timex, re.IGNORECASE):\n",
    "            day = hashweekdays[timex.split()[1]]\n",
    "            timex_val = str(base_date + RelativeDateTime(weeks=+1, \\\n",
    "                              weekday=(day,0)))\n",
    "\n",
    "        # Last, this, next week.\n",
    "        elif re.match(r'last week', timex, re.IGNORECASE):\n",
    "            year = (base_date + RelativeDateTime(weeks=-1)).year\n",
    "\n",
    "            # iso_week returns a triple (year, week, day) hence, retrieve\n",
    "            # only week value.\n",
    "            week = (base_date + RelativeDateTime(weeks=-1)).iso_week[1]\n",
    "            timex_val = str(year) + 'W' + str(week)\n",
    "        elif re.match(r'this week', timex, re.IGNORECASE):\n",
    "            year = (base_date + RelativeDateTime(weeks=0)).year\n",
    "            week = (base_date + RelativeDateTime(weeks=0)).iso_week[1]\n",
    "            timex_val = str(year) + 'W' + str(week)\n",
    "        elif re.match(r'next week', timex, re.IGNORECASE):\n",
    "            year = (base_date + RelativeDateTime(weeks=+1)).year\n",
    "            week = (base_date + RelativeDateTime(weeks=+1)).iso_week[1]\n",
    "            timex_val = str(year) + 'W' + str(week)\n",
    "\n",
    "        # Month in the previous year.\n",
    "        elif re.match(r'last ' + month, timex, re.IGNORECASE):\n",
    "            month = hashmonths[timex.split()[1]]\n",
    "            timex_val = str(base_date.year - 1) + '-' + str(month)\n",
    "\n",
    "        # Month in the current year.\n",
    "        elif re.match(r'this ' + month, timex, re.IGNORECASE):\n",
    "            month = hashmonths[timex.split()[1]]\n",
    "            timex_val = str(base_date.year) + '-' + str(month)\n",
    "\n",
    "        # Month in the following year.\n",
    "        elif re.match(r'next ' + month, timex, re.IGNORECASE):\n",
    "            month = hashmonths[timex.split()[1]]\n",
    "            timex_val = str(base_date.year + 1) + '-' + str(month)\n",
    "        elif re.match(r'last month', timex, re.IGNORECASE):\n",
    "\n",
    "            # Handles the year boundary.\n",
    "            if base_date.month == 1:\n",
    "                timex_val = str(base_date.year - 1) + '-' + '12'\n",
    "            else:\n",
    "                timex_val = str(base_date.year) + '-' + str(base_date.month - 1)\n",
    "        elif re.match(r'this month', timex, re.IGNORECASE):\n",
    "                timex_val = str(base_date.year) + '-' + str(base_date.month)\n",
    "        elif re.match(r'next month', timex, re.IGNORECASE):\n",
    "\n",
    "            # Handles the year boundary.\n",
    "            if base_date.month == 12:\n",
    "                timex_val = str(base_date.year + 1) + '-' + '1'\n",
    "            else:\n",
    "                timex_val = str(base_date.year) + '-' + str(base_date.month + 1)\n",
    "        elif re.match(r'last year', timex, re.IGNORECASE):\n",
    "            timex_val = str(base_date.year - 1)\n",
    "        elif re.match(r'this year', timex, re.IGNORECASE):\n",
    "            timex_val = str(base_date.year)\n",
    "        elif re.match(r'next year', timex, re.IGNORECASE):\n",
    "            timex_val = str(base_date.year + 1)\n",
    "        elif re.match(r'\\d+ days? (ago|earlier|before)', timex, re.IGNORECASE):\n",
    "\n",
    "            # Calculate the offset by taking '\\d+' part from the timex.\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            timex_val = str(base_date + RelativeDateTime(days=-offset))\n",
    "        elif re.match(r'\\d+ days? (later|after)', timex, re.IGNORECASE):\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            timex_val = str(base_date + RelativeDateTime(days=+offset))\n",
    "        elif re.match(r'\\d+ weeks? (ago|earlier|before)', timex, re.IGNORECASE):\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            year = (base_date + RelativeDateTime(weeks=-offset)).year\n",
    "            week = (base_date + \\\n",
    "                            RelativeDateTime(weeks=-offset)).iso_week[1]\n",
    "            timex_val = str(year) + 'W' + str(week)\n",
    "        elif re.match(r'\\d+ weeks? (later|after)', timex, re.IGNORECASE):\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            year = (base_date + RelativeDateTime(weeks=+offset)).year\n",
    "            week = (base_date + RelativeDateTime(weeks=+offset)).iso_week[1]\n",
    "            timex_val = str(year) + 'W' + str(week)\n",
    "        elif re.match(r'\\d+ months? (ago|earlier|before)', timex, re.IGNORECASE):\n",
    "            extra = 0\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "\n",
    "            # Checks if subtracting the remainder of (offset / 12) to the base month\n",
    "            # crosses the year boundary.\n",
    "            if (base_date.month - offset % 12) < 1:\n",
    "                extra = 1\n",
    "\n",
    "            # Calculate new values for the year and the month.\n",
    "            year = str(base_date.year - offset // 12 - extra)\n",
    "            month = str((base_date.month - offset % 12) % 12)\n",
    "\n",
    "            # Fix for the special case.\n",
    "            if month == '0':\n",
    "                month = '12'\n",
    "            timex_val = year + '-' + month\n",
    "        elif re.match(r'\\d+ months? (later|after)', timex, re.IGNORECASE):\n",
    "            extra = 0\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            if (base_date.month + offset % 12) > 12:\n",
    "                extra = 1\n",
    "            year = str(base_date.year + offset // 12 + extra)\n",
    "            month = str((base_date.month + offset % 12) % 12)\n",
    "            if month == '0':\n",
    "                month = '12'\n",
    "            timex_val = year + '-' + month\n",
    "        elif re.match(r'\\d+ years? (ago|earlier|before)', timex, re.IGNORECASE):\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            timex_val = str(base_date.year - offset)\n",
    "        elif re.match(r'\\d+ years? (later|after)', timex, re.IGNORECASE):\n",
    "            offset = int(re.split(r'\\s', timex)[0])\n",
    "            timex_val = str(base_date.year + offset)\n",
    "\n",
    "        # Remove 'time' from timex_val.\n",
    "        # For example, If timex_val = 2000-02-20 12:23:34.45, then\n",
    "        # timex_val = 2000-02-20\n",
    "        timex_val = re.sub(r'\\s.*', '', timex_val)\n",
    "\n",
    "        # Substitute tag+timex in the text with grounded tag+timex.\n",
    "        tagged_text = re.sub('<TIMEX2>' + timex_ori + '</TIMEX2>', '<TIMEX2 val=\\\"' \\\n",
    "            + timex_val + '\\\">' + timex_ori + '</TIMEX2>', tagged_text)\n",
    "\n",
    "    return tagged_text\n",
    "\n",
    "####\n",
    "\n",
    "def demo():\n",
    "    import nltk\n",
    "    text = appendFilesData[1][\"Body\"] #nltk.corpus.abc.raw(appendFilesData[1][\"Body\"])[:10000]\n",
    "    print(tag(text))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
